{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMLHTSK8E+CxY38wlAfsxGr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thepersonuadmire/-Logistic-Regression/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theoretical\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cOqA7CQhGjPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Logistic Regression is a statistical method used for binary classification that predicts the probability of a binary outcome based on one or more predictor variables.\n",
        "\n",
        "Difference:\n",
        "\n",
        "Linear Regression predicts continuous outcomes, while Logistic Regression predicts probabilities that are then mapped to binary outcomes (0 or 1)."
      ],
      "metadata": {
        "id": "R41-xVqeGq6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. The equation is : [ P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n)}} ]\n",
        "\n",
        "Where ( P(Y=1|X) ) is the probability of the positive class, ( \\beta_0 ) is the intercept, and ( \\beta_1, \\beta_2, ..., \\beta_n ) are the coefficients for the predictor variables ( X_1, X_2, ..., X_n )."
      ],
      "metadata": {
        "id": "Q_zPPQaNHOYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. The Sigmoid function maps any real-valued number into the range (0, 1), making it suitable for modeling probabilities. It ensures that the output can be interpreted as a probability of the positive class."
      ],
      "metadata": {
        "id": "ZDqf-K3MHWoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. The cost function used in Logistic Regression is the Log Loss (or Binary Cross-Entropy Loss): [ J(\\beta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\beta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\beta(x^{(i)}))] ]\n",
        "\n",
        "Where ( h_\\beta(x) ) is the predicted probability, ( y^{(i)} ) is the actual label, and ( m ) is the number of samples.\n"
      ],
      "metadata": {
        "id": "ufLbjt5bHaGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Regularization is a technique used to prevent overfitting by adding a penalty term to the cost function.\n",
        "\n",
        "It is needed to improve the model's generalization to unseen data by discouraging overly complex models."
      ],
      "metadata": {
        "id": "vQdZglukHeOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Lasso (L1 Regularization): Adds a penalty equal to the absolute value of the coefficients. It can shrink some coefficients to zero, effectively performing variable selection.\n",
        "\n",
        "Ridge (L2 Regularization): Adds a penalty equal to the square of the coefficients. It shrinks coefficients but does not set them to zero.\n",
        "\n",
        "Elastic Net: Combines both L1 and L2 penalties, allowing for both variable selection and coefficient shrinkage."
      ],
      "metadata": {
        "id": "15QV72FJHixr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Use Elastic Net when there are multiple features that are correlated with each other. It can handle situations where Lasso might select one feature and ignore others, while Ridge might include all features but with small coefficients."
      ],
      "metadata": {
        "id": "39UxzDo9HpP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. The regularization parameter ( \\lambda ) controls the strength of the penalty applied to the coefficients. A larger ( \\lambda ) increases the penalty, leading to smaller coefficients and potentially underfitting, while a smaller ( \\lambda ) allows for more complex models.\n"
      ],
      "metadata": {
        "id": "oENz53YvHtXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. The key assumptions are :\n",
        "\n",
        "\n",
        "*   The dependent variable is binary.\n",
        "*   The observations are independent.\n",
        "*   There is a linear relationship between the logit of the outcome and the predictor variables.\n",
        "*  No multicollinearity among the independent variables.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wQrtslRtHwO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.\n",
        "*   Decision Trees\n",
        "*   Random Forests\n",
        "*  Support Vector Machines (SVM)\n",
        "*   k-Nearest Neighbors (k-NN)\n",
        "*   Neural Networks\n",
        "\n"
      ],
      "metadata": {
        "id": "O8XKu2yuIRfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.\n",
        "*   Accuracy\n",
        "*   Precision\n",
        "*   Recall (Sensitivity)\n",
        "*   F1-Score\n",
        "*   ROC-AUC Score\n",
        "*   Confusion Matrix\n"
      ],
      "metadata": {
        "id": "T9-ojADBIqA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Class imbalance can lead to biased predictions towards the majority class, resulting in poor performance on the minority class. It can affect metrics like accuracy, making them misleading."
      ],
      "metadata": {
        "id": "aZXhOVKpI89J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Hyperparameter tuning involves optimizing the parameters that govern the learning process (like regularization strength ( C ) and penalty type) to improve model performance."
      ],
      "metadata": {
        "id": "dHwVjD73JAbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Common solvers include:\n",
        "\n",
        "liblinear: Good for small datasets.\n",
        "\n",
        "saga: Works well with large datasets and supports L1 and L2 regularization.\n",
        "\n",
        "lbfgs: Efficient for large datasets and supports L2 regularization.\n",
        "\n",
        "\n",
        "*  The choice of solver depends on the dataset size and the type of regularization needed.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tyGdsFFwJWIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Logistic Regression can be extended using:\n",
        "\n",
        "One-vs-Rest (OvR): Trains one classifier per class.\n",
        "\n",
        "Softmax Regression: Generalizes logistic regression to multiple classes by using the softmax function."
      ],
      "metadata": {
        "id": "oFKJUZ6dJgsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Advantages:\n",
        "\n",
        "Simple and easy to implement.\n",
        "\n",
        "Interpretable coefficients.\n",
        "\n",
        "Works well with linearly separable data.\n",
        "\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Assumes linearity between the logit and predictors.\n",
        "\n",
        "Sensitive to outliers.\n",
        "\n",
        "Limited to binary outcomes (without extensions)."
      ],
      "metadata": {
        "id": "7ezRty_xJpwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.\n",
        "*   Email spam detection\n",
        "*   Credit scoring\n",
        "*   Disease diagnosis\n",
        "*  Customer churn prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "sGnXpNNyJwVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Logistic Regression is used for binary classification, while Softmax Regression is used for multiclass classification, providing probabilities for each class."
      ],
      "metadata": {
        "id": "Imz21UWGKAb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Use OvR when the classes are not mutually exclusive or when the number of classes is large. Use Softmax when classes are mutually exclusive and the dataset is not too large."
      ],
      "metadata": {
        "id": "WCF0KngdKD57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. The coefficients represent the change in the log odds of the outcome for a one-unit increase in the predictor variable, holding all other variables constant."
      ],
      "metadata": {
        "id": "fdsrqOQHKGt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical"
      ],
      "metadata": {
        "id": "1Qe8ZGcRKKET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "bU8-H3cOL05W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "iwGh9nQhL4Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2."
      ],
      "metadata": {
        "id": "dK33awgRL3fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')  # Replace 'dataset.csv' with your actual dataset file\n",
        "\n",
        "# Assume the target variable is named 'target'\n",
        "X = data.drop('target', axis=1)  # Features\n",
        "y = data['target']  # Target variable\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with L1 regularization (Lasso)\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')  # 'liblinear' is required for L1 penalty\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with L1 Regularization: {accuracy}')"
      ],
      "metadata": {
        "id": "Wmn2AzDSL7rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3."
      ],
      "metadata": {
        "id": "ejmgiMvSL8La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with L2 Regularization: {accuracy}')\n",
        "print(f'Coefficients: {model.coef_}')"
      ],
      "metadata": {
        "id": "ppHTEwQpL9KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4."
      ],
      "metadata": {
        "id": "b3lNyk9YL9dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with Elastic Net Regularization\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with Elastic Net Regularization: {accuracy}')"
      ],
      "metadata": {
        "id": "S-zBZx23L-G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5."
      ],
      "metadata": {
        "id": "O5veq5-mL-yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('multiclass_dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression for multiclass classification\n",
        "model = LogisticRegression(multi_class='ovr')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy for Multiclass Classification: {accuracy}')"
      ],
      "metadata": {
        "id": "0iAc_ZtML_ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6."
      ],
      "metadata": {
        "id": "HWdbG6TaL_wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "grid = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = grid.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Best Parameters: {grid.best_params_}')\n",
        "print(f'Model Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "MdQj-DkcMAj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7."
      ],
      "metadata": {
        "id": "R0Ixkx6rMA34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Set up Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Evaluate using cross-validation\n",
        "scores = cross_val_score(model, X, y, cv=skf)\n",
        "print(f'Average Accuracy: {scores.mean()}')"
      ],
      "metadata": {
        "id": "0ciwvHFEMBvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8."
      ],
      "metadata": {
        "id": "WzArI8QCMCEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "7MEfKkbhMDFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9."
      ],
      "metadata": {
        "id": "TJYjf1n7MDYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "param_distributions = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
        "random_search = RandomizedSearchCV(LogisticRegression(), param_distributions, n_iter=10, cv=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = random_search.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Best Parameters: {random_search.best_params_}')\n",
        "print(f'Model Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "YpoTcuF-MEIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10."
      ],
      "metadata": {
        "id": "EAhUU74QMFCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('multiclass_dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train One-vs-One Logistic Regression\n",
        "model = OneVsOneClassifier(LogisticRegression())\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy for One-vs-One Multiclass Classification: {accuracy}')"
      ],
      "metadata": {
        "id": "KsaXkOdqMGFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11."
      ],
      "metadata": {
        "id": "MGyu-pEuMGYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Logistic Regression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PFeJkCQtMHea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12."
      ],
      "metadata": {
        "id": "bkmChxsmMICu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')"
      ],
      "metadata": {
        "id": "7w1PF1dqMI-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13."
      ],
      "metadata": {
        "id": "ElNVEUzcMJdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('imbalanced_dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with class weights\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with Class Weights: {accuracy}')"
      ],
      "metadata": {
        "id": "wIBJfcWXMKpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14."
      ],
      "metadata": {
        "id": "5RR0NSpTMLpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Titanic dataset\n",
        "data = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "data.drop(columns=['Cabin', 'Ticket', 'Name'], inplace=True)\n",
        "\n",
        "# Convert categorical variables\n",
        "data = pd.get_dummies(data, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "# Split dataset\n",
        "X = data.drop('Survived', axis=1)\n",
        "y = data['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy on Titanic Dataset: {accuracy}')"
      ],
      "metadata": {
        "id": "0MM743xnMMrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15."
      ],
      "metadata": {
        "id": "jrkndLqdMM-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data .drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression without scaling\n",
        "model_no_scaling = LogisticRegression()\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression with scaling\n",
        "model_with_scaling = LogisticRegression()\n",
        "model_with_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_with_scaling = model_with_scaling.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "\n",
        "print(f'Model Accuracy without Scaling: {accuracy_no_scaling}')\n",
        "print(f'Model Accuracy with Scaling: {accuracy_with_scaling}')"
      ],
      "metadata": {
        "id": "XN6EBXelMORO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16."
      ],
      "metadata": {
        "id": "CLv1oB5QMOkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate using ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f'ROC-AUC Score: {roc_auc}')"
      ],
      "metadata": {
        "id": "EqI3dinEMPlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17."
      ],
      "metadata": {
        "id": "KrWuHc2WMP3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with custom learning rate\n",
        "model = LogisticRegression(C=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with Custom Learning Rate: {accuracy}')"
      ],
      "metadata": {
        "id": "pqmsk89uMRAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18."
      ],
      "metadata": {
        "id": "S4A3BGTRMRO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance\n",
        "importance = model.coef_[0]\n",
        "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importance})\n",
        "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print('Feature Importance:')\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "id": "m4NZ2WhYMSqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19."
      ],
      "metadata": {
        "id": "S50WV2OEMTG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train , y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate using Cohen’s Kappa Score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(f'Cohen’s Kappa Score: {kappa_score}')"
      ],
      "metadata": {
        "id": "3dWvqRf0MUK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20."
      ],
      "metadata": {
        "id": "ql8ONStZMUn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fF-2TOfhMV40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21."
      ],
      "metadata": {
        "id": "VO-DNgRbMW9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'Model Accuracy with {solver} solver: {accuracy}')"
      ],
      "metadata": {
        "id": "DdrczY9hMX7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22."
      ],
      "metadata": {
        "id": "_ba0qf7FMYQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate using Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f'Matthews Correlation Coefficient: {mcc}')"
      ],
      "metadata": {
        "id": "iT__QLstMZBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23."
      ],
      "metadata": {
        "id": "RsOE8h9LMZce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression on raw data\n",
        "model_raw = LogisticRegression()\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression on standardized data\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred pred_scaled)\n",
        "\n",
        "print(f'Model Accuracy on Raw Data: {accuracy_raw}')\n",
        "print(f'Model Accuracy on Standardized Data: {accuracy_scaled}')"
      ],
      "metadata": {
        "id": "GsziEHUDMb1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24."
      ],
      "metadata": {
        "id": "BxIMOUFJMcVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up GridSearchCV for optimal C\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = grid.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Optimal C: {grid.best_params_[\"C\"]}')\n",
        "print(f'Model Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "FWL1fJ6XMdLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25."
      ],
      "metadata": {
        "id": "IudWta8JMeG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('dataset.csv')\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'logistic_regression_model.joblib')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = joblib.load('logistic_regression_model.joblib')\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy after Loading: {accuracy}')"
      ],
      "metadata": {
        "id": "5hvtO-_-Me_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}